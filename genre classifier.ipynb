{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JLjHF0skVJCF"},"outputs":[],"source":["import json\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow.keras as keras"]},{"cell_type":"markdown","metadata":{"id":"ZpbgmiUTiM_y"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NCRrIP_rV3SL"},"outputs":[],"source":["Data_path = 'data.json'\n","def load_data(Data_path):\n","  with open(Data_path, 'r') as fp:\n","    data = json.load(fp)\n","  X = np.array(data['mfcc'])\n","  y = np.array(data['labels'])\n","  return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7ayXgykaJ4W"},"outputs":[],"source":["def prepare_datasets(test_size, validation_size):\n","  #load data\n","\n","  X , y = load_data(Data_path)\n","\n","  #create train/test split\n","  X_train,  X_test, y_train, y_test = train_test_split(X,y, test_size=test_size)\n","  #create train/valid split\n","  X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = validation_size)\n","\n","\n","  #3d array (130, 13, 1)\n","  X_train = X_train[..., np.newaixs]\n","  X_validation = X_validation[..., np.newaixs]\n","  X_test = X_test[..., np.newaixs] #adds extra axis #4d array\n","  #num samples, 130, 13, 1\n","\n","  return  X_train, X_validation, X_test, y_train, y_validation, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtJ-2W-ad2_7"},"outputs":[],"source":["def build_model(input_shape):\n","\n","\n","  #create model\n","\n","  model = keras.sequential()\n"," #1st conv layer\n","  model.add(keras.layers.Conv2D(32, (3,3) , activation = 'relu', input_shape = input_shape))\n","  model.add(keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same'))\n","  model.add(keras.layers.BatchNormalization())\n","\n","#2nd conv layer\n","  model.add(keras.layers.Conv2D(32, (3,3) , activation = 'relu', input_shape = input_shape))\n","  model.add(keras.layers.MaxPool2D((3,3), strides = (2,2), padding = 'same'))\n","  model.add(keras.layers.BatchNormalization())\n","\n","#3rd conv layer\n","  model.add(keras.layers.Conv2D(32, (2,2) , activation = 'relu', input_shape = input_shape))\n","  model.add(keras.layers.MaxPool2D((2,2), strides = (2,2), padding = 'same'))\n","  model.add(keras.layers.BatchNormalization())\n","\n","  #flatten and feed into dense layer\n","  model.add(keras.layers.Flatten())\n","  model.add(keras.layers.Dense(64, activation='relu'))\n","  model.add(keras.layers.Dropout(0.3)) #30% probability for dropout - stop overfitting\n","\n","\n","  #output layer using softmax\n","  model.add(keras.layers.Dense(10, activation='softmax')) #10 neurons - one for each genre, softmax gives partition function for each genre\n","\n","  return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pc8Arwt4jcch"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"authorship_tag":"ABX9TyPRuSpkSB8uhqFdj9Mj5dkH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}